#!/bin/bash
# Quick deployment script for Airflow on EC2

set -e

echo "ğŸš€ Airflow Deployment Script"
echo "=============================="

# Check if .env exists
if [ ! -f .env ]; then
    echo "âŒ .env file not found!"
    echo "ğŸ“ Creating .env from .env.example..."
    cp .env.example .env
    echo "âš ï¸  Please edit .env and add your AWS credentials"
    echo "   nano .env"
    exit 1
fi

# Create directories
echo "ğŸ“ Creating directories..."
mkdir -p dags logs plugins scripts data/raw

# Set permissions for Airflow user
echo "ğŸ” Setting permissions..."
echo -e "AIRFLOW_UID=$(id -u)" >> .env

# Start Airflow
echo "ğŸ³ Starting Airflow with Docker Compose..."
docker-compose up -d

echo ""
echo "â³ Waiting for Airflow to start (30 seconds)..."
sleep 30

# Check status
echo ""
echo "ğŸ“Š Checking Airflow status..."
docker-compose ps

echo ""
echo "âœ… Airflow is running!"
echo ""
echo "ğŸŒ Access Airflow UI:"
echo "   - SSH Tunnel: ssh -L 8080:localhost:8080 ec2-user@YOUR_EC2_IP"
echo "   - Then open: http://localhost:8080"
echo "   - Login: airflow / airflow"
echo ""
echo "ğŸ“ Useful commands:"
echo "   - View logs: docker-compose logs -f"
echo "   - Stop: docker-compose down"
echo "   - Restart: docker-compose restart"
echo ""
